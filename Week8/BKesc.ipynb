{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-29T03:16:00.387172Z","iopub.execute_input":"2023-05-29T03:16:00.387708Z","iopub.status.idle":"2023-05-29T03:16:00.419454Z","shell.execute_reply.started":"2023-05-29T03:16:00.387664Z","shell.execute_reply":"2023-05-29T03:16:00.418536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"/kaggle/input/gdsc-hongik-aiml-kaggle-comptetion/GDSC_train.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:13:54.165112Z","iopub.execute_input":"2023-05-29T07:13:54.165486Z","iopub.status.idle":"2023-05-29T07:13:54.338980Z","shell.execute_reply.started":"2023-05-29T07:13:54.165458Z","shell.execute_reply":"2023-05-29T07:13:54.338138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntot_features = df.drop(['default'], axis=1)\ntot_labels = df['default']\n\nX_train, X_val, y_train, y_val = train_test_split(tot_features, tot_labels, test_size=0.2)\nprint(\"üëÄSize of each datas...üëÄ\")\nprint(f\"X_train : {X_train.shape}\")\nprint(f\"X_val : {X_val.shape}\")\nprint(f\"y_train : {y_train.shape}\")\nprint(f\"y_val : {y_val.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:40:16.938105Z","iopub.execute_input":"2023-05-29T07:40:16.939177Z","iopub.status.idle":"2023-05-29T07:40:16.957949Z","shell.execute_reply.started":"2023-05-29T07:40:16.939135Z","shell.execute_reply":"2023-05-29T07:40:16.956225Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"üëÄSize of each datas...üëÄ\nX_train : (19200, 23)\nX_val : (4800, 23)\ny_train : (19200,)\ny_val : (4800,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import xgboost as xgb\n\nX = df.iloc[:, :-1]\ny = df.iloc[:, -1]\n\nxgbc = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\nxgbc.fit(X_train, y_train)\n\nfeature_importance = xgbc.feature_importances_\ncolumns = df.columns[:-1]\n\nsorted_idx = feature_importance.argsort()[::-1]\n\n# Ï§ëÏöîÎèÑ ÏàúÏúºÎ°ú Ï†ïÎ†¨ ÌõÑ Ï∂úÎ†•\nfor idx in sorted_idx:\n    print(f\"{columns[idx]}: {feature_importance[idx]}\")\n\n# ÏµúÏÜå Ï§ëÏöîÎèÑÎ•º Í∞ÄÏßÑ Ïó¥ Ï∂úÎ†•\nprint(f\"Least important column: {columns[sorted_idx[-1]]}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:40:21.857224Z","iopub.execute_input":"2023-05-29T07:40:21.857643Z","iopub.status.idle":"2023-05-29T07:40:24.466624Z","shell.execute_reply.started":"2023-05-29T07:40:21.857610Z","shell.execute_reply":"2023-05-29T07:40:24.465411Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"PAY_1: 0.33635038137435913\nPAY_2: 0.11954481154680252\nPAY_3: 0.05531349405646324\nPAY_4: 0.043061502277851105\nPAY_5: 0.03907407075166702\nPAY_6: 0.029392952099442482\nPAY_AMT2: 0.025603098794817924\nBILL_AMT1: 0.025338396430015564\nLIMIT_BAL: 0.025113165378570557\nPAY_AMT3: 0.024696677923202515\nPAY_AMT5: 0.02352241985499859\nPAY_AMT1: 0.023116257041692734\nBILL_AMT3: 0.022979477420449257\nBILL_AMT4: 0.02255413867533207\nBILL_AMT2: 0.02246742509305477\nBILL_AMT5: 0.022102437913417816\nEDUCATION: 0.022093741223216057\nPAY_AMT4: 0.021953778341412544\nPAY_AMT6: 0.021362800151109695\nBILL_AMT6: 0.02022741548717022\nMARRIAGE: 0.019211888313293457\nAGE: 0.018052376806735992\nSEX: 0.016867266967892647\nLeast important column: SEX\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### ScalerÏóê Îî∞Î•∏ ÏÑ±Îä• ÎπÑÍµê","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\n\nscaler1 = StandardScaler()\nX_train_std = scaler1.fit_transform(X_train)\nX_val_std = scaler1.transform(X_val)\n\nscaler2 = MinMaxScaler()\nX_train_norm = scaler2.fit_transform(X_train)\nX_val_norm = scaler2.transform(X_val)\n\n\nscaler3 = RobustScaler()\nX_train_rob = scaler3.fit_transform(X_train)\nX_val_rob = scaler3.transform(X_val)\n\nsvm_model = svm.SVC()\n\n# ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞\nsvm_model.fit(X_train, y_train)\ny_pred = svm_model.predict(X_val)\nprint(f\"Accuracy (original): {accuracy_score(y_val, y_pred)}\")\n\n# StandardScaler\nsvm_model.fit(X_train_std, y_train)\ny_pred_std = svm_model.predict(X_val_std)\nprint(f\"Accuracy (standardized): {accuracy_score(y_val, y_pred_std)}\")\n\n# MinMaxScaler\nsvm_model.fit(X_train_norm, y_train)\ny_pred_norm = svm_model.predict(X_val_norm)\nprint(f\"Accuracy (normalized): {accuracy_score(y_val, y_pred_norm)}\")\n\n# Robust\nsvm_model.fit(X_train_rob, y_train)\ny_pred_rob = svm_model.predict(X_val_rob)\nprint(f\"Accuracy (Robust): {accuracy_score(y_val, y_pred_rob)}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:52:00.740069Z","iopub.execute_input":"2023-05-29T07:52:00.740451Z","iopub.status.idle":"2023-05-29T07:53:12.814389Z","shell.execute_reply.started":"2023-05-29T07:52:00.740425Z","shell.execute_reply":"2023-05-29T07:53:12.813347Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Accuracy (original): 0.7791666666666667\nAccuracy (standardized): 0.8214583333333333\nAccuracy (normalized): 0.8222916666666666\nAccuracy (Robust): 0.82125\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import accuracy_score\n\n\nmodels = [\n    LogisticRegression(solver='liblinear'),\n    SVC(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(random_state=42),\n    xgb.XGBClassifier(task_type='CPU', random_state=42),\n    LGBMClassifier(random_state=42),\n    CatBoostClassifier(task_type='CPU', random_seed=42, silent=True),\n    KNeighborsClassifier()\n]\n\nX = df.iloc[:, :-1]\ny = df.iloc[:, -1]\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\ncv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\nfor model in models:\n    print(f\"{model.__class__.__name__}\")\n    scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='accuracy')\n    print(f\"Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:44:04.063214Z","iopub.execute_input":"2023-05-29T07:44:04.063600Z","iopub.status.idle":"2023-05-29T07:47:14.744122Z","shell.execute_reply.started":"2023-05-29T07:44:04.063572Z","shell.execute_reply":"2023-05-29T07:47:14.742951Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"LogisticRegression\nAccuracy: 0.8106 (+/- 0.0024)\n\nSVC\nAccuracy: 0.8205 (+/- 0.0049)\n\nDecisionTreeClassifier\nAccuracy: 0.7305 (+/- 0.0195)\n\nRandomForestClassifier\nAccuracy: 0.8150 (+/- 0.0041)\n\nXGBClassifier\n[07:46:17] WARNING: ../src/learner.cc:767: \nParameters: { \"task_type\" } are not used.\n\n[07:46:20] WARNING: ../src/learner.cc:767: \nParameters: { \"task_type\" } are not used.\n\n[07:46:23] WARNING: ../src/learner.cc:767: \nParameters: { \"task_type\" } are not used.\n\n[07:46:26] WARNING: ../src/learner.cc:767: \nParameters: { \"task_type\" } are not used.\n\n[07:46:29] WARNING: ../src/learner.cc:767: \nParameters: { \"task_type\" } are not used.\n\nAccuracy: 0.8152 (+/- 0.0069)\n\nLGBMClassifier\nAccuracy: 0.8215 (+/- 0.0046)\n\nCatBoostClassifier\nAccuracy: 0.8202 (+/- 0.0029)\n\nKNeighborsClassifier\nAccuracy: 0.7932 (+/- 0.0030)\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### LGBMClassifier ÏÇ¨Ïö©Ìï¥ ÌïôÏäµ Î∞è Ï∂îÎ°†","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_std = scaler.fit_transform(X_train)\nX_val_std = scaler.transform(X_val)\n\nlgbm = LGBMClassifier(random_state=42)\n\ncv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\nfold_accuracy = []\n\nfor train_idx, val_idx in cv.split(X_train_std, y_train):\n    X_train_fold, X_val_fold = X_train_std[train_idx], X_train_std[val_idx]\n    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n    lgbm.fit(X_train_fold, y_train_fold)\n    y_val_pred = lgbm.predict(X_val_fold)\n    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n    fold_accuracy.append(val_accuracy)\n\nprint(f\"Validation Accuracy per Fold: {fold_accuracy}\")\nprint(f\"Average Validation Accuracy: {np.mean(fold_accuracy):.4f}\")\n\n# ÏµúÏ¢Ö Î™®Îç∏ ÌïôÏäµ Î∞è ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Ï∂îÎ°†\nlgbm.fit(X_train_std, y_train)\ny_val_pred = lgbm.predict(X_val_std)\nval_accuracy = accuracy_score(y_val, y_val_pred)\nprint(f\"\\nval Accuracy: {val_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:51:21.202105Z","iopub.execute_input":"2023-05-29T07:51:21.203533Z","iopub.status.idle":"2023-05-29T07:51:23.737533Z","shell.execute_reply.started":"2023-05-29T07:51:21.203486Z","shell.execute_reply":"2023-05-29T07:51:23.736448Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Validation Accuracy per Fold: [0.8322916666666667, 0.8203125, 0.8161458333333333, 0.8174479166666667, 0.8197916666666667]\nAverage Validation Accuracy: 0.8212\n\nval Accuracy: 0.8204\n","output_type":"stream"}]},{"cell_type":"code","source":"test_X = pd.read_csv('/kaggle/input/gdsc-hongik-aiml-kaggle-comptetion/GDSC_test.csv')\nscaled_test_X = scaler.transform(test_X)\n\ny_test_pred = lgbm.predict(scaled_test_X)\n\nsub_preds = pd.DataFrame(y_test_pred, columns=['preds'])\nsub_preds.to_csv('/kaggle/working/cv_lgbm_submission.csv', index_label='idx')\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:54:20.216707Z","iopub.execute_input":"2023-05-29T07:54:20.217126Z","iopub.status.idle":"2023-05-29T07:54:20.277426Z","shell.execute_reply.started":"2023-05-29T07:54:20.217092Z","shell.execute_reply":"2023-05-29T07:54:20.276199Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}]},{"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_std = scaler.fit_transform(X_train)\nX_val_std = scaler.transform(X_val)\n\nlgbm = LGBMClassifier(random_state=42)\n\ncv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\nfold_accuracy = []\n\nfor train_idx, val_idx in cv.split(X_train_std, y_train):\n    X_train_fold, X_val_fold = X_train_std[train_idx], X_train_std[val_idx]\n    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n    lgbm.fit(X_train_fold, y_train_fold)\n    y_val_pred = lgbm.predict(X_val_fold)\n    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n    fold_accuracy.append(val_accuracy)\n\nprint(f\"Validation Accuracy per Fold: {fold_accuracy}\")\nprint(f\"Average Validation Accuracy: {np.mean(fold_accuracy):.4f}\")\n\n# ÏµúÏ¢Ö Î™®Îç∏ ÌïôÏäµ Î∞è ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Ï∂îÎ°†\nlgbm.fit(X_train_std, y_train)\ny_val_pred = lgbm.predict(X_val_std)\nval_accuracy = accuracy_score(y_val, y_val_pred)\nprint(f\"\\nval Accuracy: {val_accuracy:.4f}\")\n\ntest_X = pd.read_csv('/kaggle/input/gdsc-hongik-aiml-kaggle-comptetion/GDSC_test.csv')\nscaled_test_X = scaler.transform(test_X)\n\ny_test_pred = lgbm.predict(scaled_test_X)\n\nsub_preds = pd.DataFrame(y_test_pred, columns=['preds'])\nsub_preds.to_csv('/kaggle/working/cv_lgbm_minmax_submission.csv', index_label='idx')\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:55:28.220982Z","iopub.execute_input":"2023-05-29T07:55:28.221393Z","iopub.status.idle":"2023-05-29T07:55:30.739138Z","shell.execute_reply.started":"2023-05-29T07:55:28.221361Z","shell.execute_reply":"2023-05-29T07:55:30.737049Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Validation Accuracy per Fold: [0.8286458333333333, 0.8213541666666667, 0.8143229166666667, 0.8166666666666667, 0.8203125]\nAverage Validation Accuracy: 0.8203\n\nval Accuracy: 0.8196\nDone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### torch ÏÇ¨Ïö©Ìïú Í≤ΩÏö∞","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\n\n# Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨\nX = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n\nscaler = StandardScaler()\nX_train_std = scaler.fit_transform(X_train)\nX_val_std = scaler.transform(X_val)\n\n# Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ Î≥ÄÌôò\nX_train_torch = torch.tensor(X_train_std, dtype=torch.float32)\ny_train_torch = torch.tensor(y_train, dtype=torch.long)\nX_val_torch = torch.tensor(X_val_std, dtype=torch.float32)\ny_val_torch = torch.tensor(y_val, dtype=torch.long)\n\ntrain_dataset = TensorDataset(X_train_torch, y_train_torch)\nval_dataset = TensorDataset(X_val_torch, y_val_torch)\n\ntrain_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dl = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Î™®Îç∏ ÏÑ§Í≥Ñ\nclass SimpleClassifier(nn.Module):\n    def __init__(self, input_features, output_classes):\n        super(SimpleClassifier, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_features, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, output_classes),\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\n\nmodel = SimpleClassifier(X_train_torch.shape[1], len(np.unique(y_train_torch.numpy())))\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# Î™®Îç∏ ÌïôÏäµ\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    for xb, yb in train_dl:\n        optimizer.zero_grad()\n        outputs = model(xb)\n        loss = criterion(outputs, yb)\n        loss.backward()\n        optimizer.step()\n\n    if epoch % 10 == 0:\n        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\nwith torch.no_grad():\n    test_preds = model(X_val_torch)\n    _, predicted_labels = torch.max(test_preds, dim=1)\n\n    accuracy = (predicted_labels == y_val_torch).float().mean().numpy()\n    print(f\"\\nTest Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:34:32.739558Z","iopub.execute_input":"2023-05-29T07:34:32.740651Z","iopub.status.idle":"2023-05-29T07:37:59.824988Z","shell.execute_reply.started":"2023-05-29T07:34:32.740606Z","shell.execute_reply":"2023-05-29T07:37:59.824044Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch [1/100], Loss: 0.5409\nEpoch [11/100], Loss: 0.3558\nEpoch [21/100], Loss: 0.4957\nEpoch [31/100], Loss: 0.3725\nEpoch [41/100], Loss: 0.2425\nEpoch [51/100], Loss: 0.1096\nEpoch [61/100], Loss: 0.1258\nEpoch [71/100], Loss: 0.3029\nEpoch [81/100], Loss: 0.2744\nEpoch [91/100], Loss: 0.0968\n\nTest Accuracy: 0.7754\n","output_type":"stream"}]},{"cell_type":"code","source":"test_X = pd.read_csv('/kaggle/input/gdsc-hongik-aiml-kaggle-comptetion/GDSC_test.csv')\nscaled_test_X = scaler.transform(test_X)\nX_test_torch = torch.tensor(scaled_test_X, dtype=torch.float32)\n\nwith torch.no_grad():\n    test_preds = model(X_test_torch)\n    _, predicted_labels = torch.max(test_preds, dim=1)\nsub_preds = pd.DataFrame(predicted_labels, columns=['preds'])\nsub_preds.to_csv('/kaggle/working/dl_submission.csv', index_label='idx')\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2023-05-29T07:37:59.826441Z","iopub.execute_input":"2023-05-29T07:37:59.827078Z","iopub.status.idle":"2023-05-29T07:37:59.905666Z","shell.execute_reply.started":"2023-05-29T07:37:59.827045Z","shell.execute_reply":"2023-05-29T07:37:59.904162Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}