{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 기초  \n",
    "\n",
    "![](./main.jpg)  \n",
    "이제 본격적으로! 머신러닝에 대해 공부해볼 겁니다. 아마 많은 분들이 이 컨텐츠에 대해 관심을 가지고 스터디를 신청하셨을 거 같아요 ㅎㅎ 하지만 데이터에 대해 익숙해지지 않은 상태로 바로 머신러닝과 인공지능에 들어가면 그 흐름을 이해하지도 못한 채, 정말 의미 없이 여러분의 시간을 날려버릴 가능성이 매우 높습니다. 비유를 하자면.. 사칙연산을 배우지도 않고 미분부터 하는 느낌정도? \n",
    "  \n",
    "아무튼! 여기까지 배운 내용들을 잘 해결하셨다면, 이제부터 하는 내용은 **\"코드적으로는\"** 그렇게 어렵지 않을 거예요! 지금부터는 코드를 연습한다는 느낌보다는 `개념의 흐름을 더 중요하게` 생각하시고 공부하시는 게 얻어가는 게 더 많을 겁니다. \n",
    "  \n",
    "나중에 짜게 되실 복잡한 딥러닝 코드들도, 결국 이러한 흐름을 코드로 표현한 것에 불과하니까요!  \n",
    "  \n",
    "머신러닝 컨텐츠는 3주에 걸쳐 진행됩니다. 그 중 첫 주차인 오늘은, 머신러닝의 간단한 흐름과 그 과정들을 대표적인 도구인 `sklearn`을 통해 배워볼 거예요!  \n",
    "  \n",
    "`sklearn`을 통해 가장 간단한 데이터셋에 대해 분류 작업을 수행해보고, 간단하게 흐름 정도만 파악하겠습니다. 학습에 있어서 데이터의 어떤 특성이 요구되는지, 그런 특성들을 어떻게 만들 수 있는지는 다음주차인 `지도학습` 시간에 다뤄보도록 할게요! \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "**알림**\n",
    "- 본 컨텐츠는 강의 형식이 아닌, 스스로 공부하시는 분들을 위한 일종의 문제집 입니다.\n",
    "- 데이터라는 큰 바다에서 여러분이 쓸 데 없는 시간 낭비 없이 바로바로 핵심을 배우실 수 있도록 커리큘럼을 짜봤습니다.\n",
    "- 이 컨텐츠의 문제들만 해결한다고 실력이 오르지 않습니다. 본 컨텐츠의 목적은 문제를 해결하는 과정에서 발생하는 고민과 질문을 통한 실력 향상입니다. \n",
    "- 문제에서 절대 떠먹여주지 않습니다. 물고기를 잡아주는 것이 아닌, 물고기를 잡는 방법을 여러분이 이 컨텐츠를 통해 알아가셨으면 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 분류 프로젝트 해보기\n",
    "머신러닝은 별 게 아닙니다. 모여진 데이터들에서 정해진 패턴을 파악하는 걸 있어보이게 머신러닝이라고 이름을 붙인 것뿐입니다.  \n",
    "  \n",
    "예를 들어, 우리가 다뤘던 데이터인 펭귄데이터셋도 생각해보면 그런 느낌이었죠.  \n",
    "> 부리의 길이가 x, 두께는 y, 몸무게는 z, 사는 지역은 k 인 펭귄의 종은 A   \n",
    "\n",
    "이런 식의 어떤 대상(Target)과 대상이이 가지는 특징(Feature)들의 관계를 파악하는 게 바로 머신러닝입니다.\n",
    "  \n",
    "> 내가 예전에 학습한 데이터에 의하면... 부리의 길이가 x'고 두께는 y'고 몸무게는 z', 사는 지역은 k' 이니까.... 이 펭귄의 종은 A겠군!  \n",
    "\n",
    " 라고 할 수 있도록 우리는 기계를 학습시키는 게 우리의 목표인 것이죠.  \n",
    "  \n",
    "그래서 **Machine Learning**이기도 하구요. 그럼, 기계는 어떻게 학습시킬 수 있을까요? 한번 가장 기초적인 과정을 따라가봅시다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1 데이터 불러오기\n",
    "위에서 말씀 드렸다 싶이, 머신러닝은 데이터가 가지는 특징(Feature)과 그래서 그 데이터가 뭔지(Target) 사이의 패턴을 파악하는 일입니다.  \n",
    "  \n",
    "이번 시간에는 간단하게, 유방암의 여부를 예측해보는 Task를 해볼 겁니다.   \n",
    "아래 코드를 실행시켜, 유방암 데이터를 받아주세요  \n",
    "  \n",
    "<br>\n",
    "\n",
    "```python\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "dataset = pd.concat([X, y], axis=1)\n",
    "dataset\n",
    "```\n",
    "  \n",
    "<br>\n",
    "  \n",
    "데이터를 받아주신 뒤, 이 데이터의 Feature는 어떤지, Label은 어떤지 설명해주세요.  \n",
    "다시 말해, 이 데이터는 어떤 목표를 가지고 구축된 데이터인지 말씀해주세요!\n",
    "\n",
    "_예시_  \n",
    "![](./1-1answer.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "dataset = pd.concat([X, y], axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       mean radius  mean texture  mean perimeter    mean area  \\\n",
       " count   569.000000    569.000000      569.000000   569.000000   \n",
       " mean     14.127292     19.289649       91.969033   654.889104   \n",
       " std       3.524049      4.301036       24.298981   351.914129   \n",
       " min       6.981000      9.710000       43.790000   143.500000   \n",
       " 25%      11.700000     16.170000       75.170000   420.300000   \n",
       " 50%      13.370000     18.840000       86.240000   551.100000   \n",
       " 75%      15.780000     21.800000      104.100000   782.700000   \n",
       " max      28.110000     39.280000      188.500000  2501.000000   \n",
       " \n",
       "        mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       " count       569.000000        569.000000      569.000000           569.000000   \n",
       " mean          0.096360          0.104341        0.088799             0.048919   \n",
       " std           0.014064          0.052813        0.079720             0.038803   \n",
       " min           0.052630          0.019380        0.000000             0.000000   \n",
       " 25%           0.086370          0.064920        0.029560             0.020310   \n",
       " 50%           0.095870          0.092630        0.061540             0.033500   \n",
       " 75%           0.105300          0.130400        0.130700             0.074000   \n",
       " max           0.163400          0.345400        0.426800             0.201200   \n",
       " \n",
       "        mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       " count     569.000000              569.000000  ...     569.000000   \n",
       " mean        0.181162                0.062798  ...      25.677223   \n",
       " std         0.027414                0.007060  ...       6.146258   \n",
       " min         0.106000                0.049960  ...      12.020000   \n",
       " 25%         0.161900                0.057700  ...      21.080000   \n",
       " 50%         0.179200                0.061540  ...      25.410000   \n",
       " 75%         0.195700                0.066120  ...      29.720000   \n",
       " max         0.304000                0.097440  ...      49.540000   \n",
       " \n",
       "        worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       " count       569.000000   569.000000        569.000000         569.000000   \n",
       " mean        107.261213   880.583128          0.132369           0.254265   \n",
       " std          33.602542   569.356993          0.022832           0.157336   \n",
       " min          50.410000   185.200000          0.071170           0.027290   \n",
       " 25%          84.110000   515.300000          0.116600           0.147200   \n",
       " 50%          97.660000   686.500000          0.131300           0.211900   \n",
       " 75%         125.400000  1084.000000          0.146000           0.339100   \n",
       " max         251.200000  4254.000000          0.222600           1.058000   \n",
       " \n",
       "        worst concavity  worst concave points  worst symmetry  \\\n",
       " count       569.000000            569.000000      569.000000   \n",
       " mean          0.272188              0.114606        0.290076   \n",
       " std           0.208624              0.065732        0.061867   \n",
       " min           0.000000              0.000000        0.156500   \n",
       " 25%           0.114500              0.064930        0.250400   \n",
       " 50%           0.226700              0.099930        0.282200   \n",
       " 75%           0.382900              0.161400        0.317900   \n",
       " max           1.252000              0.291000        0.663800   \n",
       " \n",
       "        worst fractal dimension      target  \n",
       " count               569.000000  569.000000  \n",
       " mean                  0.083946    0.627417  \n",
       " std                   0.018061    0.483918  \n",
       " min                   0.055040    0.000000  \n",
       " 25%                   0.071460    0.000000  \n",
       " 50%                   0.080040    1.000000  \n",
       " 75%                   0.092080    1.000000  \n",
       " max                   0.207500    1.000000  \n",
       " \n",
       " [8 rows x 31 columns],\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(), dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"target\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유방암 유무가 target으로 나타나고\n",
    "여러 수치들을 이용해 유방암 유무를 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 train_test_split\n",
    "\n",
    "머신러닝을 훈련시킬 때는 머신러닝이 패턴을 학습할 `학습데이터`와 모델의 성능을 학습과정에서 평가하기 위한 `검증데이터`, 마지막으로 최종적으로 실전 투입에서의 성능을 평가하기 위한 `테스트데이터`가 필요합니다.\n",
    "  \n",
    "쉽게 비유하면, 수능이라는 점수를 잘 내기 위해서 평소에 1월 ~ 8월 모의고사로 공부를 하고, 9월 모의고사로 \"아 대충 이정도 나오겠구나~\"로 생각하죠?  \n",
    "여기서 1월에서 8월까지의 모의고사를 `학습데이터`라고 할 수 있고, 실전은 아니지만 실전 상황을 가정하고 우리의 실력을 확인해보기 위해 사용한 9월 모의고사 성적을 `검증데이터`, 그리고 수능을 `테스트데이터`라고 할 수 있습니다.\n",
    "  \n",
    "실전에선, 데이터 한 뭉텅이만 있고, 우리는 그 데이터에 대해 학습시킨 다음, 미래에 들어올 미지의 데이터를 예측해야합니다.  \n",
    "즉, 환자 500명의 데이터만을 가지고, 앞으로 들어올 환자(기존의 500명에는 포함 안 되어 있는 새로운 환자)의 데이터만을 가지고 유방암이 걸렸는지 안 걸렸는지 예측을 해내야 한다는 것이죠. \n",
    "  \n",
    "그래서!! 일단 가지고 있는 데이터를 **분리**시켜야 합니다.  \n",
    "위에서 말했던 그대로, 이 모델이 어느 정도의 성능이 될 지 미리 알아둘 필요가 있기 때문이죠.  \n",
    "  \n",
    "`sklearn`의 `train_test_split`을 이용하면, 쉽게 처리할 수 있습니다.\n",
    "  \n",
    "아래 예시 코드의 빈 칸에 들어갈 함수를 입력하고, 학습 데이터와 검증 데이터를 나눠주세요!  \n",
    "  \n",
    "**단, 검증데이터의 비율은 0.2, random_state=42로 고정시켜주세요.**\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = \"\"\"HERE YOUR CODE\"\"\"\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_val: {X_test.shape}\")\n",
    "print(f\"Shape of y_val: {y_test.shape}\")\n",
    "```\n",
    "  \n",
    "__예시__  \n",
    "![](./1-2answer.png)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (455, 30)\n",
      "Shape of X_val: (114, 30)\n",
      "Shape of y_train: (455,)\n",
      "Shape of y_val: (114,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_val: {X_val.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 O, X퀴즈\n",
    "- 위에서 분리해낸 X_val과 y_val은 학습 과정에 사용되어, 모델의 패턴 학습에 활용된다 (O, X)  \n",
    "🙅‍♀️ 땡!!!! 검증 데이터셋은 말 그대로 모델의 성능을 실전에 투입되기 전에 테스트해보기 위한 용도입니다. 즉, 실전을 가정하는 데이터셋이라는 것이죠. 우리가 9월 모의고사로 실력을 테스트해보려고 하는데 9월 모의고사 문제와 답안지를 미리 알고 있으면 안 된다는 얘기입니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing 전처리\n",
    "데이터셋 분리에 성공했다면, 이제 전처리를 해주어야 합니다.  \n",
    "전처리를 모델의 성능을 가르는 가장 큰 요소로, 사실 어떤 모델을 썼냐~ 세부 설정은 뭐로 했냐~ 이런 거보다 데이터 전처리를 바꾸는 게 성능을 가장 크게 바꾼답니다.  \n",
    "  \n",
    "\n",
    "> **\"Garbage in, Garbage out!!\"**  \n",
    "\n",
    "Data Driven 사고에 대해서 조금 더 알고 싶으시다면, [여기](https://www.techopedia.com/whats-the-difference-between-model-driven-ai-and-data-driven-ai/7/34776)에서 한번 쭉 읽어보시는 것도 흥미진진 하실거예요 ㅎㅎ\n",
    "  \n",
    "그런 만큼, 전처리는 모델의 전체적인 과정에 있어 가장 오랜 시간을 들여야 하는 파트입니다.  \n",
    "  \n",
    "쉽게 비유를 하면, 우리가 여자친구나 남자친구에게 크리스마스에 파스타를 만들어주려고 한다고 해봅시다.  \n",
    "그럼, 장을 보고~ 재료 정리하고~ 재료 다듬고~ 요리하고~ 서빙하고~ 이 과정을 거치는데, 실제로 어디에서 가~~장 시간이 많이 쇼요될까요?  \n",
    "  \n",
    "맞아요 사실 장을보고 재료를 다듬는 과정까지가 제일 오래 걸린답니다. 실제로 요리하는 시간은 생각보다 오래 걸리지 않거든요 ㅎㅎ   \n",
    "  \n",
    "우리가 모델링 하는 걸 요리로 비유했을 때, **재료를 다듬는 과정까지를 전처리**라고 할 수 있습니다. 하지만 동시에 **가장 중요한 과정**이라고 할 수 있습니다.\n",
    "사실 4주에 걸쳐 데이터를 핸들링하는 방법에 대해 배운 이유는, 바로 이 전처리에 걸리는 시간을 좀 줄이기 위해서도 없지 않아 있어요 ㅎㅎ..  \n",
    "  \n",
    "가장 오래 걸리고 이런 저런 생각을 많이 해야하는 파트지만, 우리는 튜토리얼이니까 조금 간단하게 `결측치 제거`와 `Scaling`만 보고 넘어가보도록 할게요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 null값 삭제\n",
    "데이터를 학습하는 데에 있어서 null값(결측치)는 도움이 되지 않습니다. 오히려 학습을 방해하거나 혼동을 줄 수 있죠.  \n",
    "결측치를 다루는 방법은 여러가지가 있습니다.  \n",
    "  \n",
    "> 1. 삭제하기\n",
    "> 2. 다른 값으로 대체하기  \n",
    ">     2-1. 통계값(평균값, 최빈값, 중앙값..)  \n",
    ">     2-2. EDA를 통해 알아낸 사실로 대체하기 (필사할 때 아셨죠?)  \n",
    "  \n",
    "이 외에도 다양한 방법이 있지만 일단 우리는 여기서 가장 간단한 방법인 `삭제하기` 로 실습해보도록  \n",
    "  \n",
    "**우리가 사용하는 데이터에는 결측치가 없기 때문에, 일단 나름대로 Data Frame을 생성해보고, 결측치를 제거하는 코드를 실습해볼게요!**\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(100, 5), columns=[\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "\n",
    "for _ in range(10):\n",
    "    row_idx = np.random.choice(df.index)\n",
    "    col_idx = np.random.choice(df.columns)\n",
    "    df.loc[row_idx, col_idx] = np.nan\n",
    "\n",
    "print(f\"🔎 # of NaN Values :\\n {df.isnull().sum()}\")\n",
    "print(f\"Shape of Data Frame : {df.shape}\")\n",
    "\n",
    "> HERE YOUR CODE!\n",
    "\n",
    "print(f\"🚀 결측치 처리 후 :\\n {df.isnull().sum()}\")\n",
    "print(f\"Shape of Data Frame : {df.shape}\")\n",
    "```\n",
    "\n",
    "검색 힌트 : pd.dropna(), pd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 # of NaN Values :\n",
      " A    5\n",
      "B    0\n",
      "C    1\n",
      "D    3\n",
      "E    1\n",
      "dtype: int64\n",
      "Shape of Data Frame : (100, 5)\n",
      "🚀 결측치 처리 후 :\n",
      " A    0\n",
      "B    0\n",
      "C    0\n",
      "D    0\n",
      "E    0\n",
      "dtype: int64\n",
      "Shape of Data Frame : (90, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(100, 5), columns=[\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "\n",
    "for _ in range(10):\n",
    "    row_idx = np.random.choice(df.index)\n",
    "    col_idx = np.random.choice(df.columns)\n",
    "    df.loc[row_idx, col_idx] = np.nan\n",
    "\n",
    "print(f\"🔎 # of NaN Values :\\n {df.isnull().sum()}\")\n",
    "print(f\"Shape of Data Frame : {df.shape}\")\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "print(f\"🚀 결측치 처리 후 :\\n {df.isnull().sum()}\")\n",
    "print(f\"Shape of Data Frame : {df.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 Scaling 하기  \n",
    "모델의 안정적인 학습을 위해서는 `데이터의 단위를 통일` 시켜주는 것이 좋습니다.  \n",
    "이유는 다음과 같아요!\n",
    "    \n",
    "> 1. Feature간의 상대적 중요도가 더 잘 드러납니다.  \n",
    "> 2. 이상치의 영향력이 감소합니다.  \n",
    "> 3. 연산 효율이 좋아집니다.  \n",
    "    \n",
    "조금 더 직관적인 설명을 드려볼게요.  \n",
    "우리가 만약 주택의 가격을 예측하는 업무를 맡았다고 해볼게요!  \n",
    "주택의 가격을 결정하는 Feature들로 __\"방 개수\", \"주택 평수\"__ 를 설정했다고 해봅시다.  \n",
    "  \n",
    "근데 생각해보면 **방 개수**는 해봐야 1~5개 정도로, **주택 평수**는 1 ~ 100까지 뭐 다양하겠죠?  \n",
    "**즉, 다시 말해 두 데이터간의 범위에 있어서 차이가 발생합니다.**  \n",
    "   \n",
    "그럼, 머신러닝이 이를 학습할 때 어떤 문제가 발생할까요?  \n",
    "  \n",
    "> 🤖: 어... 얘는... 변동폭이 크니까... 중요한가,,,? 얘는... 변동폭이 그리 안 크니까 안 중요한 거겠지,,,?\n",
    "  \n",
    "이런 식으로 오해할 수 있어요. 그러기 때문에, 일반적으로 딥러닝이나 Tree 모델을 제외한 나머지 모델로 학습을 시킬 때는 꼭 Scaling을 진행해주는 것이 좋습니다.  \n",
    "  \n",
    "### 문제\n",
    "`sklearn`의 `StandardScaler`를 이용하여 `X_train`과 `X_val`을 Scaling 해주세요.  \n",
    "\n",
    "단, X_train엔 `fit_transform()`을, X_val엔 `transform()` 메소드를 적용해서 Scaling 해주세요!  \n",
    "  \n",
    "그리고 왜 학습데이터엔 `fit_transform()`을 사용해도 되지만, 검증용이나 테스트 데이터엔 `transform()`만을 이용해야 하는지 적어주세요!\n",
    "  \n",
    "<br>\n",
    "\n",
    "Base Line  \n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = '''HERE YOUR CODE!'''\n",
    "\n",
    "scaled_X_train = '''HERE YOUR CODE!'''\n",
    "scaled_X_val = '''HERE YOUR CODE!'''\n",
    "\n",
    "scaled_X_train_check = scaled_X_train.reshape(30, -1)\n",
    "print(f\"Scaling전 데이터의 최대, 최소, 평균, std: {X_train['mean texture'].max(), X_train['mean texture'].min(),  X_train['mean texture'].mean(),  X_train['mean texture'].std()}\")\n",
    "print(f\"Scaling후 데이터의 최대, 최소, 평균, std: {scaled_X_train_check[0].max(), scaled_X_train_check[0].min(), scaled_X_train_check[0].mean(), scaled_X_train_check[0].std()}\")\n",
    "```\n",
    "  \n",
    "<br>\n",
    "\n",
    "검색 힌트 : fit_transform()과 transform()차이, sklearn Standard Scaler, sklearn Scaler 종류\n",
    "  \n",
    "_예시_  \n",
    "![](./2-2answer.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "### ❗ 심화학습 ❗   \n",
    "오잉? 트리모델은 왜 Scaling이 안 필요할까요? 그 작동방식을 한번 확인해보고, 왜 안 필요한지 WIL에 적어주세요! (어떤 형태로든 적어주시면 됩니다. md파일에 그대로 적어주셔도 되고, 블로그에 적어주셔도 되고..) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling전 데이터의 최대, 최소, 평균, std: (39.28, 9.71, 19.185032967032967, 4.266004530881453)\n",
      "Scaling후 데이터의 최대, 최소, 평균, std: (8.438936670491492, -1.4407529621170216, 0.19602811306761933, 1.1739751826530365)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "\n",
    "scaled_X_train_check = scaled_X_train.reshape(30, -1)\n",
    "print(f\"Scaling전 데이터의 최대, 최소, 평균, std: {X_train['mean texture'].max(), X_train['mean texture'].min(),  X_train['mean texture'].mean(),  X_train['mean texture'].std()}\")\n",
    "print(f\"Scaling후 데이터의 최대, 최소, 평균, std: {scaled_X_train_check[0].max(), scaled_X_train_check[0].min(), scaled_X_train_check[0].mean(), scaled_X_train_check[0].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3 학습시키기\n",
    "이제 우리가 전처리한 데이터를 학습시키는 일만 남았습니다.  \n",
    "데이터를 학습할 모델을 고르는 것도 사실 중요한 일 중 하나지만, 일단 저희는 Tree 모델 중에서 가~~~~장 기본이 되는 `DecisionTree`와 `Random Foreset`를 사용해서 성능을 비교해볼게요!  \n",
    "  \n",
    "이번 문제는 그냥 간단하게, `아~ 이런 이런 함수를 써서 학습시키고 예측하는구나~` 정도로만 알고 넘어가셔도 좋을 것같습니다.  \n",
    "  \n",
    "sklearn의 `DecisionTreeClassifier`로 `scaled_X_train`과 `y_train`을 이용해서 학습을 진행해주세요!  \n",
    "단, `DecisionTreeClassifier`의 `random_state`는 42로 고정시켜주세요.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Base Line**\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = '''HERE YOUR CODE!!'''\n",
    "\n",
    "classifier.'''HERE YOUR CODE!!'''\n",
    "\n",
    "print(\"🤖Training is Done!\")\n",
    "```  \n",
    "\n",
    "<br>\n",
    "\n",
    "검색 힌트: sklearn DecisionTree, sklearn 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "classifier.fit(scaled_X_train, y_train)\n",
    "print(\"Training is Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4 예측하기\n",
    "2-3에서 모델을 우리 데이터에 맞게 학습시켰습니다. 이제 그럼 이 학습된 모델이 실전에서 잘 작동할 수 있는지 확인해봐야겠죠?  \n",
    "학습된 모델을 기반으로 데이터를 넣어 prediction을 구할 수 있습니다.  \n",
    "  \n",
    "2-4에서 학습시킨 모델로 `scaled_X_val`을 예측해주세요!  \n",
    "그리고 모델의 정확도(Accuracy)가 얼마나 되는지, `sklearn`의 `accuracy_score`를 통해 계산해주세요!  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Base Line**\n",
    "```python\n",
    "from sklearn.metrics import '''HERE YOUR CODE!!'''\n",
    "\n",
    "predictions = classifier.'''HERE YOUR CODE!!'''\n",
    "accuracy = '''HERE YOUR CODE!!'''\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "검색 힌트: sklearn 모델 predict, sklearn 정확도 계산  \n",
    "  \n",
    "_예시_  \n",
    "![](./2-4answer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.94737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = classifier.predict(scaled_X_val)\n",
    "accuarcy = accuracy_score(y_val, predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {accuarcy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5 다른 모델도 써보기\n",
    "우리는 `DecisionTree`알고리즘을 통해 94% 라는 높은 정확도를 얻어냈습니다.  \n",
    "그럼 Ensemble 모델의 원조할머니급인 `Random Forest`의 성능도 한번 확인해볼까요?  \n",
    "  \n",
    "랜덤포레스트로 학습과 예측, 정확도 계산까지의 코드를 완성해주세요!  \n",
    "단, `RandomForestClassifier`의 random_state는 42로 고정해주세요.\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import '''HERE YOUR CODE!!'''\n",
    "\n",
    "rf_clf = '''HERE YOUR CODE!!'''\n",
    "rf_clf.'''HERE YOUR CODE!!'''\n",
    "rf_prediction = rf_clf.'''HERE YOUR CODE!!'''\n",
    "\n",
    "rf_acc = '''HERE YOUR CODE!!'''\n",
    "print(f\"Random Forest Model Accuracy: {rf_acc}\")\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "검색 힌트: sklearn Random Forest\n",
    "  \n",
    "_예시_  \n",
    "![](./2-5answer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.96491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(scaled_X_train, y_train)\n",
    "rf_prediction = rf_clf.predict(scaled_X_val)\n",
    "\n",
    "rf_acc = accuracy_score(y_val, rf_prediction)\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 심화 학습\n",
    "우리는 방금 Decision Tree와 Random Forest의 결과를 비교해봤습니다. 분명 같은 데이터로 두 모델을 학습시켰는데, Random Forest의 정확도가 조금 더 높게 나왔습니다.  \n",
    "**왜 그 럴 까 요?**  \n",
    "Random Forest는 이름에서도 느껴졌듯이, Tree가 여러개 모인 모델입니다.  \n",
    "하나보단 둘이 더 낫고, 셋보단 넷, 넷보단 여러명이 더 나을 때가 있죠. 우리가 함께 모여 팀프로젝트를 하는 이유가 바로 그거구요.  \n",
    "  \n",
    "왜 Random Forest가 Decision Tree보다 더 나은 성능을 보이는지 공부한 결과를 블로그에 정리하신 뒤, 해당 링크를 `@자기혁명왕`에게 보내주세요!  \n",
    "  \n",
    "힌트는 **`Ensemble`** 입니다. 딥러닝에서도 쓰이는 아주 중요한 개념이니, 심화학습이긴 하지만 한번 쯤은 쓱-- 공부라도 하시는 걸 추천드려용 ㅎㅎ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest는 여러 다른 의사결정트리를 만들어 결과를 다수결로 결정한다.\n",
    "\n",
    "각 Tree들이 다양한 시각에서 데이터를 관찰, 학습하기 때문에\n",
    "뛰어난 부분은 더 향상되고 취약한 부분을 보완할 수 있다.\n",
    "\n",
    "그래서 개별 모델로 학습한 경우에 비해 Overfitting을 막을 수 있고 일반화 성능도 향상시킬 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5주차 종료 \n",
    "머신러닝의 가장 일반적인 흐름을 살펴봤습니다. 어떤가요? 생각보다 코드들이 막 그렇게 복잡하지는 않죠?  \n",
    "맞습니다. 사실 `pytorch`나 `tensorflow`와 같은 딥러닝에 특화된 프레임워크가 아닌 `sklearn`은 그렇게 복잡한 코드를 요구하지는 않습니다.  \n",
    "  \n",
    "때문에, 코드적 스킬보다는 그 코드가 의미하는 것, 그리고 개념이 더 중요하다고 할 수 있죠.  \n",
    "  \n",
    "사실 성능도 코드를 어떻게 잘 지지고 볶았냐에서 갈린다고 하기 보다는 데이터 전처리를 얼마나 알맞게 잘 했냐, 어떤 아이디어를 적용시켰냐! 가 사실은 성능에 있어서 더 큰 영향을 주더라구용  \n",
    "  \n",
    "위의 과정에서 나온 `Scaling`, `fit`과 `fit_transform()`의 차이, `결측치 처리 방법` 모두 머신러닝을 할 때 성능을 가를 수 있는 중요한 요소들입니다.  \n",
    "시간 되실 때, 꼭 한번쯤은 복습하시는 걸 추천드려요 ㅎㅎ\n",
    "  \n",
    "## 숙제 \n",
    "시험기간인 만큼, 큰 부담은 최대한 안 드리려고 합니다.  \n",
    "여러분이 위의 과정을 하시면서 배운 것들을 블로그에 정리한 뒤, md 파일에 블로그 링크를 함께 달아주세요!  \n",
    "  \n",
    "궁금하신 게 생기시면 언제든지 편하게 질문주세요 ㅎㅎ 그럼 다음에 봐요! \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "768016c7aa7eaabec9016402577e4cabb606e332b3187c608d53990dc1c3c37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
